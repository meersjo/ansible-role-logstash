input {
  beats {
    port => 5050
  }
}

filter {
  # Filebeat zet het type afhankelijk van de bronfile.
  #--------------------type = sessions--------------------
  if [type] == "sessions" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "%{DATA:TS-temp};%{WORD:openclose};%{WORD:username};%{UUID:accesskey}(;%{DATA:TS-open2};%{GREEDYDATA:duration})?" ]
    }
    # Timestamp omzetten naar ZULU timestamp en in het juiste field zetten.
    if [openclose] == "CLOSE" {
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy/MM/dd HH:mm:ss" ]
        target => "TS-close"
      }
      mutate {
        update => { "TS-temp" => "%{TS-open2}" }
        remove_field => [ "TS-open2" ]
      }
    }
    # Timestamps omzetten naar ZULU timestamp en in het juiste field zetten.
    date {
      timezone => "Europe/Brussels"
      match => [ "TS-temp", "yyyy/MM/dd HH:mm:ss" ]
      target => "TS-open"
    }
    # Overbodige velden weggooien.
    mutate {
      remove_field => [ "TS-temp", "openclose" ]
    }
  }
  #--------------------type = lighttable_loadtimes--------------------
  if [type] == "lighttable_loadtimes" {
    grok {
      match => [ "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} ### End Lighttable: Server Elapsed Time:%{NUMBER:load-time:int} ms" ]
    }
    # Timestamps omzetten naar ZULU timestamp en in het juiste field zetten.
    date {
      timezone => "Europe/Brussels"
      match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss" ]
      target => "TS-logged"
    }
    # Overbodige velden weggooien.
    mutate {
      remove_field => [ "TS-temp" ]
    }
  }
  #--------------------type = video_analyses--------------------
  if [type] == "video_analyses" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] %{GREEDYDATA}<DMGuid>%{GREEDYDATA:DMGuid}</DMGuid>%{GREEDYDATA}<AnalysisType>%{WORD:AnalysisType}</AnalysisType>",
                 "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] material frame size: %{GREEDYDATA:ARvideo}",
                 "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] keyframe size to extract: %{GREEDYDATA:ARkeyframe}",
                 "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] Duration: %{NUMBER:VideoLength:int} ms$",
                 "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] analysis completed in %{NUMBER:AnalysisDuration:int}",
                 "message", "\[%{TIMESTAMP_ISO8601:datum}\] \[%{WORD}\] \[%{NUMBER}\] extracted keyframes: %{NUMBER:AantalKeyframes:int}" ]
    }
    # Extract workflowID from source field.
    grok {
      match => [ "source", "%{GREEDYDATA}%{UUID:WorkflowID}\.log"  ]
    }
    # Overbodige velden weggooien.
    mutate {
      remove_field => [ "message" ]
    }
    # Onnodige loglijnen weggooien.
    if "_grokparsefailure" in [tags] {
      drop {}
    }
  }

  #--------------------type = process_import--------------------
  if [type] == "process_import" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "%{TIMESTAMP_ISO8601:TS-temp} DMGUID=%{GREEDYDATA:DMGuid};ObjectClass=%{WORD:ObjectClass};Mediatype=%{WORD:Mediatype};FileSize=%{NUMBER:Filesize};Duration=%{NUMBER:Duration}." ]
    }

   # Filesize omzetten naar int 
    mutate {
      convert => { "Filesize" => "float" }
      convert => { "Duration" => "float" }
    }
    

   # Timestamp omzetten naar ZULU timestamp en in het juiste field zetten.
    date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss.SSS" ]
        target => "TS-logged"
    }

   # Overbodige velden weggooien.
    mutate {
      remove_field => [ "TS-temp" ]
    }
    
    # Extract workflowID from source field.
    grok {
      match => [ "source", "%{UUID:WorkflowID}\.log"  ]
    }
  }

  #--------------------type = datamanager--------------------
  if [type] == "datamanager" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} \[Req%{NUMBER:ReqNumber:int}\] Calling %{GREEDYDATA:Request} \(caller:",
                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601} %{NUMBER} \[Req%{NUMBER:ReqNumber:int}\] %{GREEDYDATA} executed in %{TIME:duration}",
                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} \[Req%{NUMBER:ReqNumber:int}\]\[#%{NUMBER:CmdNumber:int}\] command=\"%{GREEDYDATA:command}\"",
                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601} %{NUMBER} \[Req%{NUMBER:ReqNumber:int}\]\[#%{NUMBER:CmdNumber:int}\] \[user-readable command, DM uses SQL parameters\]\n%{GREEDYDATA:user-readable_command}",
                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601} %{NUMBER} \[Req%{NUMBER:ReqNumber:int}\]\[#%{NUMBER:CmdNumber:int}\] SQL execution time: %{TIME:duration}",
                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} Query:\n%{GREEDYDATA:SearchRequest}"      ]
    }
    # Type updaten.
    if [CmdNumber] {
      mutate {
        update => { "type" => "datamanager_command" }
      }
    }
    else if [ReqNumber] {
      mutate {
        update => { "type" => "datamanager_call" }
      }
    }
    
    if[SearchRequest]
    {
       
      mutate {
           update => { "type" => "datamanager_search" }
           remove_tag => [ "beats_input_codec_plain_applied" ]
      }
      xml {
        source => "SearchRequest"
        target => "xmldata"
        store_xml => "false"
        xpath => ["/AXFRoot/MAObject[@type='DMQuery']/GUID/text()","SearchType"]
        xpath => ["/AXFRoot/MAObject[@type='DMQuery']/Meta[@name='OBJECTCLASSES']/text()","ObjectClassesAll"]
        xpath => ["/AXFRoot/MAObject[@type='DMQuery']/Meta[@name='SIMPLESEARCH']/text()","SearchTerm"]
        xpath => ["/AXFRoot/MAObject[@type='DMQuery']/Meta[@name='HITLISTID']/text()","tmpHitlistId"]
        xpath => ["/AXFRoot/MAObject[@type='DMQuery']/Meta[@name='FIRSTHIT']/text()","FirstHit"]
#        xpath => ["/AXFRoot/MAObject[@type='AttributeSearch']/Meta[@name='ATTRIBUTE%']/text()","SearchAttributesAll"]
       xpath => ["/AXFRoot/MAObject[@type='AttributeSearch']/Meta[starts-with(@name, 'ATTRIBUTE')]/text()","SearchAttributesAll"]
      }
      if [tmpHitlistId]
      {
         mutate{
            add_field => { "Hitlist" => "%{tmpHitlistId}" }
         }
          if [Hitlist] == "PA_DEFAULTPROCESSES" or [Hitlist] == "VRT_HITLIST" or [Hitlist] == "PA_PROCESS_WITHOUT_USER" or [Hitlist] == "Process monitoring" or [Hitlist] == "VRT_DMGUIDONLY" {
         drop {}
         }
      }
      else
      {
         mutate
         {
            add_field => { "Hitlist" => "LEEG" }
         }
      }    
      if [SearchAttributesAll]
      {
         mutate{
            add_field => { "SearchAttributesCheck" => "%{SearchAttributesAll}" }
         }
         ruby { code => "event.set('SearchAttributesApart', event.get('SearchAttributesCheck').split(','))" }
      }
      else
      {
         mutate
         {
            add_field => { "SearchAttributesAll" => "LEEG" }
            add_field => { "SearchAttributesApart" => "LEEG" }
         }
      }      
      mutate {
         add_field => { "ObjectClassesCheck" => "%{ObjectClassesAll}" }
      }
      
      ruby { code => "event.set('ObjectClassesApart', event.get('ObjectClassesCheck').split(','))" }
      


    }
    # duration omzetten van hh:mm:ss.mmmmmmm naar ssss.mmmmmmm
    if [duration] {
      dissect {
        mapping => { "duration" => "%{hh}:%{mm}:%{ss}" }
        convert_datatype => { hh => "int"
                              mm => "int"
                              ss => "float" }
      }
      ruby { code => "event.set('duration', event.get('hh') * 3600 + event.get('mm') * 60 + event.get('ss'))" }
    }
    # Timestamps omzetten naar ZULU timestamp en in het juiste field zetten.
    if [TS-temp] {
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss" ]
        target => "TS-logged"
      }
    }
    # Overbodige velden weggooien.
    mutate {
      remove_field => [ "message", "TS-temp", "hh", "mm", "ss" ]
    }
  }
  #--------------------type = VRT_ESBGatewayWS--------------------
  if [type] == "VRT_ESBGatewayWS" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} Handling message with body:\n%{GREEDYDATA:ESB-message}" ]
#                 "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-end} %{NUMBER} Request id:'%{NUMBER:ESB-ID:int}' status updated to '%{WORD:ESB-status}' in DB." ]
    }
    # Indien start van een nieuwe request:
    if [TS-temp] {
      # Timestamp omzetten naar ZULU timestamp.
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss" ]
        target => "TS-start"
      }
      grok {
        match => [ "ESB-message", "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><%{WORD:RequestType}%{GREEDYDATA}<correlationId>%{UUID:correlationId}</correlationId>.*<mediaId>%{GREEDYDATA:DMGuid}</mediaId>" ]
      }
    }
    # Indien einde van een request:
    else if [TS-end] {
      # Timestamp omzetten naar ZULU timestamp.
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-end", "yyyy-MM-dd HH:mm:ss" ]
        target => "TS-end"
      }
    }
    # Onnodige loglijnen weggooien.
    if "_grokparsefailure" in [tags] {
      drop {}
    }
  }
  #--------------------type = resourcerequests--------------------
  if [type] == "resourcerequests" {
    # Loglijn opsplitsen in verschillende fields.
    grok {
      match => [ "message", "\[%{WORD}\] %{TIMESTAMP_ISO8601:TS-temp} %{NUMBER} \[%{WORD:SOAPInterface}\] Webmethod %{WORD:SOAPMethod} called with params: %{GREEDYDATA:params}." ]
    }
    if [SOAPMethod] == "AddRequest" {
      grok {
        match => [ "params", "accessKey=%{UUID:accesskey}, resourceName=%{WORD:resourceName}, accessType=%{NUMBER:ReadWrite}, workflowID=%{UUID:workflowGUID}, prio=%{NUMBER:priority}, startTime=(%{DATA})?, objectID=%{DATA:DMGUID}, objectInfo=(%{DATA:Reason})?" ]
      }
      # Timestamps omzetten naar ZULU timestamp en in het juiste field zetten.
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss" ]
        target => "TS-Requested"
      }
    }
    if [SOAPMethod] == "ReleaseResource" {
      grok {
        match => [ "params", "accessKey=%{UUID:accesskey}, resourceName=%{WORD:resourceName}, workflowID=%{UUID:workflowGUID}" ]
      }
      # Timestamps omzetten naar ZULU timestamp en in het juiste field zetten.
      date {
        timezone => "Europe/Brussels"
        match => [ "TS-temp", "yyyy-MM-dd HH:mm:ss" ]
        target => "TS-Released"
      }
    }
    if [SOAPMethod] == "GetRequestDetails" {
      drop {}
    }
    # Overbodige velden weggooien.
    mutate {
      remove_field => [ "TS-temp", "SOAPMethod", "params" ]
    }
  }
}

output {
  if [type] == "sessions" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM}"
      document_id => "%{accesskey}"
      action => "update"
      doc_as_upsert => "true"
      retry_on_conflict => 4
    }
  }
  if [type] == "lighttable_loadtimes" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM}"
    }
  }
  if [type] == "video_analyses" or [type] == "process_import" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
      document_id => "%{WorkflowID}"
      action => "update"
      doc_as_upsert => "true"
      retry_on_conflict => 4
    }
  }
  if [type] == "datamanager_call" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
      document_id => "%{ReqNumber}"
      action => "update"
      doc_as_upsert => "true"
      retry_on_conflict => 4
    }
  }
  if [type] == "datamanager_command" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
      document_id => "%{ReqNumber}-%{CmdNumber}"
      action => "update"
      doc_as_upsert => "true"
      retry_on_conflict => 4
    }
  }
  if [type] == "datamanager_search" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
    }
  }
  if [type] == "VRT_ESBGatewayWS" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
#      document_id => "%{correlationId}"
#      action => "update"
#      doc_as_upsert => "true"
#      retry_on_conflict => 4
    }
  }
  if [type] == "resourcerequests" {
    elasticsearch {
      hosts => ["mgmtesprod1:9200","mgmtesprod2:9200"]
      index => "depot-%{type}-%{+YYYY.MM.dd}"
      document_id => "%{workflowGUID}-%{resourceName}"
      action => "update"
      doc_as_upsert => "true"
      retry_on_conflict => 4
    }
  }
}
